{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import json\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pay attention to the reproducibility !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain=\"Materials_Science\" # Medicine, Chemistry, Biology, Physics, Materials_Science\n",
    "data_dir=f\"./{domain}\"\n",
    "downstream_dir=\"/shared/data3/bowenj4/llm-graph-plugin/data/raw_data/maple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read processed graph\n",
    "with open(os.path.join(data_dir,'graph.json'),  'r') as fp:\n",
    "    graph = json.load(fp)\n",
    "print(graph.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "all_generated_data = {} # key: triple (question (str), answer (str)), value: generated data (List)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design questions (one type of question in one cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-hop question (EASY):\n",
    "1. Who are the authors of paper xxx?\n",
    "2. Where is paper xxx published?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## question (easy): who are the authors of paper xxx?\n",
    "\n",
    "random.seed(2023)\n",
    "\n",
    "question = 'Who are the authors of paper \"{paper_title}?\" '\n",
    "answer = \"{authors}\"\n",
    "generated_data = []\n",
    "\n",
    "paper_ids = list(graph['paper_nodes'].keys())\n",
    "random.shuffle(paper_ids)\n",
    "\n",
    "for paper_id in paper_ids:\n",
    "    paper_title = graph['paper_nodes'][paper_id]['features']['title']\n",
    "    author_ids = graph['paper_nodes'][paper_id]['neighbors']['author']\n",
    "    author_names = [graph['author_nodes'][author_id]['features']['name'] for author_id in author_ids]\n",
    "    generated_data.append({\"paper_title\":paper_title, \"authors\": ', '.join(author_names)})\n",
    "\n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2024)\n",
    "\n",
    "question = 'Where is the paper \"{paper_title}\" published?'\n",
    "answer = \"{venue}\"\n",
    "generated_data = []\n",
    "\n",
    "paper_ids = list(graph['paper_nodes'].keys())\n",
    "random.shuffle(paper_ids)\n",
    "\n",
    "for paper_id in paper_ids:\n",
    "    paper_title = graph['paper_nodes'][paper_id]['features']['title']\n",
    "\n",
    "    assert len(graph['paper_nodes'][paper_id]['neighbors']['venue']) == 1\n",
    "    venue_id = graph['paper_nodes'][paper_id]['neighbors']['venue'][0]\n",
    "    \n",
    "    venue_name = graph['venue_nodes'][venue_id]['features']['name']\n",
    "    generated_data.append({\"paper_title\":paper_title, \"venue\": venue_name})\n",
    "\n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-hop Reasoning Question (Medium)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Who collaborates with author xxx to write paper xxx?\n",
    "2. who writed both paper xxx and paper xxx?\n",
    "3. How many collaborators does author xxx have in xxx?\n",
    "4. How many papers did xxx and xxx write together?\n",
    "5. Who is the closest collaborator with author xxx?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## question (medium): Who collaborates with author xxx to write paper xxx?\n",
    "\n",
    "random.seed(2025)\n",
    "\n",
    "question = 'Who collaborates with author {author_name} to write paper \"{paper_title}\"?'\n",
    "answer = \"{collaborators}\"\n",
    "generated_data = []\n",
    "\n",
    "paper_ids = list(graph['paper_nodes'].keys())\n",
    "random.shuffle(paper_ids)\n",
    "\n",
    "for paper_id in paper_ids:\n",
    "    paper_title = graph['paper_nodes'][paper_id]['features']['title']\n",
    "    author_ids = graph['paper_nodes'][paper_id]['neighbors']['author']\n",
    "    author_names = [graph['author_nodes'][author_id]['features']['name'] for author_id in author_ids]\n",
    "    \n",
    "    if len(author_names) <= 1:\n",
    "        continue\n",
    "\n",
    "    random.shuffle(author_names)\n",
    "\n",
    "    generated_data.append({\"author_name\": author_names[0],\n",
    "                       \"paper_title\": paper_title,\n",
    "                       \"collaborators\": ', '.join(author_names[1:])})\n",
    "    \n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## question (medium): who writed both paper xxx and paper xxx?\n",
    "\n",
    "random.seed(2026)\n",
    "\n",
    "question = 'Who writed both the paper \"{paper1_title}\" and paper \"{paper2_title}\"?'\n",
    "answer = \"{authors}\"\n",
    "generated_data = []\n",
    "\n",
    "author_ids = list(graph['author_nodes'].keys())\n",
    "random.shuffle(author_ids)\n",
    "\n",
    "for author_id in author_ids:\n",
    "    paper_ids = list(graph['author_nodes'][author_id]['neighbors']['paper'])\n",
    "    random.shuffle(paper_ids)\n",
    "    if len(paper_ids) < 2:\n",
    "        continue\n",
    "\n",
    "    author_list1 = graph['paper_nodes'][paper_ids[0]]['neighbors']['author']\n",
    "    author_list2 = graph['paper_nodes'][paper_ids[1]]['neighbors']['author']\n",
    "\n",
    "    if len(set(author_list1) & set(author_list2)) > 1:\n",
    "        continue\n",
    "\n",
    "    generated_data.append({\"paper1_title\": graph['paper_nodes'][paper_ids[0]]['features']['title'],\n",
    "                            \"paper2_title\": graph['paper_nodes'][paper_ids[1]]['features']['title'],\n",
    "                            \"authors\": graph['author_nodes'][author_id]['features']['name']})\n",
    "\n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question (medium):Who is the closest collaborator with author xxx?\n",
    "\n",
    "'''\n",
    "Closeness is defined in terms of the number of collaboration together. \n",
    "The most number of collaboration a pair has, the most closest they are\n",
    "'''\n",
    "\n",
    "random.seed(2028)\n",
    "\n",
    "question = \"Who is the closest collaborator with author {author_name}? Closeness is defined in terms of the number of collaboration together.\"\n",
    "answer = \"{collaborator_name}\"\n",
    "generated_data = []\n",
    "\n",
    "author_ids = list(graph['author_nodes'].keys())\n",
    "random.shuffle(author_ids)\n",
    "\n",
    "for author_id in author_ids:\n",
    "    paper_ids = graph['author_nodes'][author_id]['neighbors']['paper']\n",
    "    collaborators_by_count = {} #key: collaborator_name, value: paper_counts\n",
    "\n",
    "    for paper_id in paper_ids:\n",
    "        collaborator_ids = graph['paper_nodes'][paper_id]['neighbors']['author']\n",
    "        collaborator_names = [graph['author_nodes'][cid]['features']['name'] for cid in collaborator_ids if cid != author_id]\n",
    "        \n",
    "        for collab in collaborator_names:\n",
    "            if collab not in collaborators_by_count:\n",
    "                collaborators_by_count[collab] = 0\n",
    "            collaborators_by_count[collab] += 1\n",
    "\n",
    "    if len(collaborators_by_count) == 0:\n",
    "        continue\n",
    "\n",
    "    sorted_collaborators = sorted(collaborators_by_count.items(), key = lambda item: item[1], reverse = True)\n",
    "    \n",
    "    if len(sorted_collaborators) > 1 and sorted_collaborators[0][1] == sorted_collaborators[1][1]:\n",
    "        continue\n",
    "    \n",
    "    author_name = graph['author_nodes'][author_id]['features']['name']\n",
    "    \n",
    "    generated_data.append({\"author_name\": author_name,\n",
    "                        \"collaborator_name\": sorted_collaborators[0][0],\n",
    "                          })\n",
    "\n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question (medium): How many collaborators does author xxx have in xxx?\n",
    "\n",
    "random.seed(2027)\n",
    "\n",
    "question = \"How many collaborators does author {author_name} have in {year}\"\n",
    "answer = \"{number}\"\n",
    "generated_data = []\n",
    "\n",
    "author_ids = list(graph['author_nodes'].keys())\n",
    "random.shuffle(author_ids)\n",
    "\n",
    "for author_id in author_ids:\n",
    "    paper_ids = graph['author_nodes'][author_id]['neighbors']['paper']\n",
    "    collaborators_by_year = defaultdict(set) #key: year, value: author_names\n",
    "\n",
    "    for paper_id in paper_ids:\n",
    "        year = graph['paper_nodes'][paper_id]['features']['year']\n",
    "        collaborator_ids = graph['paper_nodes'][paper_id]['neighbors']['author']\n",
    "        collaborator_names = [graph['author_nodes'][cid]['features']['name'] for cid in collaborator_ids]\n",
    "        collaborators_by_year[year].update(collaborator_names)\n",
    "\n",
    "    author_name = graph['author_nodes'][author_id]['features']['name']\n",
    "    \n",
    "    years = [y for y in collaborators_by_year]\n",
    "    random.shuffle(years)\n",
    "    \n",
    "    generated_data.append({\"author_name\": author_name,\n",
    "                        \"year\": years[0],\n",
    "                        \"number\": len(collaborators_by_year[years[0]])-1})\n",
    "\n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: How many papers did xxx and xxx write together?\n",
    "\n",
    "random.seed(2028)\n",
    "\n",
    "question = \"How many papers did {author_name1} and {author_name2} write together?\"\n",
    "answer = \"{number}\"\n",
    "generated_data = []\n",
    "\n",
    "author_ids = list(graph['author_nodes'].keys())\n",
    "random.shuffle(author_ids)\n",
    "\n",
    "for author_id1 in author_ids:\n",
    "    curr_author_ids = list(graph['author_nodes'].keys())\n",
    "    random.shuffle(curr_author_ids)\n",
    "    for author_id2 in curr_author_ids:\n",
    "\n",
    "        if author_id1 == author_id2: \n",
    "            continue\n",
    "        \n",
    "        paper_ids1 = graph['author_nodes'][author_id1]['neighbors']['paper']\n",
    "        paper_ids2 = graph['author_nodes'][author_id2]['neighbors']['paper']\n",
    "\n",
    "        if len(set(paper_ids1) & set(paper_ids2)) < 2:\n",
    "            continue\n",
    "\n",
    "        author_name1 = graph['author_nodes'][author_id1]['features']['name']\n",
    "        author_name2 = graph['author_nodes'][author_id2]['features']['name']\n",
    "\n",
    "        generated_data.append({\"author_name1\": author_name1,\n",
    "                            \"author_name2\": author_name2,\n",
    "                            \"number\": len(set(paper_ids1) & set(paper_ids2))})\n",
    "        break\n",
    "            \n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Degree-based reasoning (easy)\n",
    "1. How many papers cite paper xxx?\n",
    "2. How many papers do paper xxx cite?\n",
    "3. How many papers did author xxx write?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## question (medium): how many paper cite paper xxx?\n",
    "\n",
    "random.seed(2030)\n",
    "\n",
    "question = 'How many papers cite the paper \"{paper_title}\"?'\n",
    "answer = \"{num}\"\n",
    "generated_data = []\n",
    "\n",
    "paper_ids = list(graph['paper_nodes'].keys())\n",
    "random.shuffle(paper_ids)\n",
    "\n",
    "for paper_id in paper_ids:\n",
    "    paper_title = graph['paper_nodes'][paper_id]['features']['title']\n",
    "    cited_by_id = graph['paper_nodes'][paper_id]['neighbors']['cited_by']\n",
    "    if len(cited_by_id)  == 0:\n",
    "        continue\n",
    "    generated_data.append({\"paper_title\": paper_title, \"num\": len(cited_by_id)})\n",
    "    \n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "\n",
    "all_generated_data[(question, answer)] = generated_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: How many papers do paper xxx cite?\n",
    "\n",
    "random.seed(2031)\n",
    "\n",
    "question = 'How many papers does paper \"{paper_title}\" cite?'\n",
    "answer = \"{num}\"\n",
    "generated_data = []\n",
    "\n",
    "paper_ids = list(graph['paper_nodes'].keys())\n",
    "random.shuffle(paper_ids)\n",
    "\n",
    "for paper_id in paper_ids:\n",
    "    paper_title = graph['paper_nodes'][paper_id]['features']['title']\n",
    "    referred_by_id = graph['paper_nodes'][paper_id]['neighbors']['reference']\n",
    "    if len(referred_by_id) == 0:\n",
    "        continue\n",
    "    generated_data.append({\"paper_title\": paper_title, \"num\": len(referred_by_id)})\n",
    "    \n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: 4. How many papers did author xxx write?\n",
    "random.seed(2033)\n",
    "\n",
    "question = \"How many papers did author {author_name} write?\"\n",
    "answer = \"{num}\"\n",
    "generated_data = []\n",
    "\n",
    "author_ids = list(graph['author_nodes'].keys())\n",
    "random.shuffle(author_ids)\n",
    "\n",
    "for author_id in author_ids:\n",
    "    paper_ids = graph['author_nodes'][author_id]['neighbors']['paper']\n",
    "    author_name = graph['author_nodes'][author_id]['features']['name']\n",
    "    generated_data.append({\"author_name\": author_name,\n",
    "                        \"num\": len(paper_ids)})\n",
    "\n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "\n",
    "all_generated_data[(question, answer)] = generated_data\n",
    "\n",
    "#Related Question How many papers does author xxx in xxx venue?\n",
    "#Related Question How many papers does author xxx in xxx year?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### medium question\n",
    "1. Which is the most cited paper by author xxx?\n",
    "2. Which venue did author xxx and author xxx collaborate most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: Which is the most cited paper by author xxx?\n",
    "random.seed(2032)\n",
    "\n",
    "question = \"Which is the most cited paper by author {author_name}?\"\n",
    "answer = \"{paper_title}\"\n",
    "generated_data = []\n",
    "\n",
    "author_ids = list(graph['author_nodes'].keys())\n",
    "random.shuffle(author_ids)\n",
    "\n",
    "for author_id in author_ids:\n",
    "    paper_ids = graph['author_nodes'][author_id]['neighbors']['paper']\n",
    "    max_count = -1\n",
    "    max_paper_id = None\n",
    "    random.shuffle(paper_ids)\n",
    "    for paper_id in paper_ids:\n",
    "        \n",
    "        cited_by_id = graph['paper_nodes'][paper_id]['neighbors']['cited_by']\n",
    "\n",
    "        if len(cited_by_id) > max_count:\n",
    "            max_count = len(cited_by_id)\n",
    "            max_paper_id = paper_id\n",
    "    \n",
    "    paper_title = graph['paper_nodes'][max_paper_id]['features']['title']\n",
    "    author_name = graph['author_nodes'][author_id]['features']['name']\n",
    "\n",
    "    generated_data.append({\"author_name\": author_name,\n",
    "                        \"paper_title\": paper_title})\n",
    "\n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: 5. Which venue did author xxx and author xxx collaborate most?\n",
    "\n",
    "random.seed(2034)\n",
    "\n",
    "question = \"Which venue did {author_name1} and {author_name2} collaborate most?\"\n",
    "answer = \"{venue}\"\n",
    "generated_data = []\n",
    "\n",
    "author_ids = list(graph['author_nodes'].keys())\n",
    "random.shuffle(author_ids)\n",
    "\n",
    "for author_id1 in author_ids:\n",
    "    curr_author_ids = list(graph['author_nodes'].keys())\n",
    "    random.shuffle(curr_author_ids)\n",
    "    for author_id2 in curr_author_ids:\n",
    "\n",
    "        if author_id1 == author_id2: \n",
    "            continue\n",
    "        paper_ids1 = graph['author_nodes'][author_id1]['neighbors']['paper']\n",
    "        paper_ids2 = graph['author_nodes'][author_id2]['neighbors']['paper']\n",
    "\n",
    "        if len(set(paper_ids1) & set(paper_ids2)) < 1:\n",
    "            continue\n",
    "\n",
    "        count_per_venue = {}\n",
    "        max_count = -1\n",
    "        max_venue = None\n",
    "        common_paper_ids = list(set(paper_ids1) & set(paper_ids2))\n",
    "\n",
    "        for paper_id in common_paper_ids:\n",
    "            venue = graph['paper_nodes'][paper_id]['neighbors']['venue'][0]\n",
    "            if venue not in count_per_venue:\n",
    "                count_per_venue[venue] = 0\n",
    "            \n",
    "            count_per_venue[venue] += 1\n",
    "            if max_count < count_per_venue[venue]:\n",
    "                max_count = count_per_venue[venue]\n",
    "                max_venue = venue\n",
    "\n",
    "        author_name1 = graph['author_nodes'][author_id1]['features']['name']\n",
    "        author_name2 = graph['author_nodes'][author_id2]['features']['name']\n",
    "\n",
    "        generated_data.append({\"author_name1\": author_name1,\n",
    "                            \"author_name2\": author_name2,\n",
    "                            \"venue\": graph['venue_nodes'][max_venue]['features']['name']})\n",
    "        break\n",
    "\n",
    "    if len(generated_data) == k:\n",
    "            break\n",
    "\n",
    "all_generated_data[(question, answer)] = generated_data\n",
    "\n",
    "#Related Question: Which year did author xxx and author xxx collaborate most in?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complex structure reasoning (medium)\n",
    "1. How many people does author xxx need to know at least to know author xxx?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: 1.  How many people does author xxx need to know at least to know author xxx?\n",
    "\n",
    "random.seed(2035)\n",
    "\n",
    "question = \"How many people does author {author_name1} need to know at least to know author {author_name2}?\"\n",
    "answer = \"{number}\"\n",
    "generated_data = []\n",
    "max_hop_length = 5 # setting the maximum hop distance between two asked authors in the graph\n",
    "\n",
    "author_ids = list(graph['author_nodes'].keys())\n",
    "random.shuffle(author_ids)\n",
    "\n",
    "def get_k_hop_neighbor(cur_author, hop, dist):\n",
    "    \n",
    "    queue = [cur_author]\n",
    "    dist[cur_author] = 0\n",
    "    \n",
    "    while(len(queue)):\n",
    "        cia = queue.pop(0)\n",
    "        cur_papers = graph['author_nodes'][cia]['neighbors']['paper']\n",
    "        cur_nids = []\n",
    "        for pid in cur_papers:\n",
    "            nids = graph['paper_nodes'][pid]['neighbors']['author']\n",
    "            cur_nids.extend(nids)\n",
    "        \n",
    "        for cin in cur_nids:\n",
    "            if cin in dist:\n",
    "                continue\n",
    "            dist[cin] = dist[cia] + 1\n",
    "            if dist[cin] == hop:\n",
    "                return cin\n",
    "            queue.append(cin)\n",
    "            \n",
    "    return -1\n",
    "\n",
    "\n",
    "for author_id in author_ids:\n",
    "    cur_hop = random.randint(1, max_hop_length)\n",
    "    neighbor = get_k_hop_neighbor(author_id, cur_hop, dict())\n",
    "    if neighbor == -1:\n",
    "        continue\n",
    "    \n",
    "    author_name1 = graph['author_nodes'][author_id]['features']['name']\n",
    "    author_name2 = graph['author_nodes'][neighbor]['features']['name']\n",
    "\n",
    "    generated_data.append({\"author_name1\": author_name1,\n",
    "                        \"author_name2\": author_name2,\n",
    "                        \"number\": cur_hop})\n",
    "                               \n",
    "    if len(generated_data) >= k:\n",
    "            break\n",
    "\n",
    "all_generated_data[(question, answer)] = generated_data\n",
    "\n",
    "#Related Question: Which year did author xxx and author xxx collaborate most in?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inductive reasoning (hard)\n",
    "1. provide a paper recommendation for paper xxx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## question (hard): provide a paper recommendation for paper xxx?\n",
    "\n",
    "random.seed(2036)\n",
    "\n",
    "# k = 3\n",
    "question = \"Which paper should be recommended to the reader of paper {paper1_title}? Please select from the candidate list {paper2_title}, {paper3_title}, {paper4_title}, {paper5_title}, {paper6_title}, {paper7_title}, {paper8_title}, {paper9_title}, {paper10_title}, {paper11_title}. Please answer the paper title rather than ID.\"\n",
    "answer = \"{paper_target_title}\"\n",
    "generated_data = []\n",
    "\n",
    "raw_pair = []\n",
    "curr_set = set()\n",
    "\n",
    "with open(os.path.join(downstream_dir, 'PaperRecommendations.txt')) as f:\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        tmp = line.strip().split('\\t')\n",
    "        if tmp[0] in graph['paper_nodes'] and tmp[1] in graph['paper_nodes'] and tmp[0] not in curr_set and tmp[1] not in curr_set:\n",
    "            raw_pair.append((tmp[0], tmp[1]))\n",
    "            curr_set.add(tmp[0])\n",
    "            curr_set.add(tmp[1])\n",
    "        if len(raw_pair) == k * 5:\n",
    "            break\n",
    "\n",
    "random.shuffle(raw_pair)\n",
    "\n",
    "paper_ids = list(graph['paper_nodes'].keys())\n",
    "for pair in raw_pair:\n",
    "    candidate_titles = []\n",
    "    candidate_titles.append(graph['paper_nodes'][pair[1]]['features']['title'])\n",
    "    random.shuffle(paper_ids)\n",
    "    candidate_titles.append(graph['paper_nodes'][paper_ids[0]]['features']['title'])\n",
    "    candidate_titles.append(graph['paper_nodes'][paper_ids[1]]['features']['title'])\n",
    "    candidate_titles.append(graph['paper_nodes'][paper_ids[2]]['features']['title'])\n",
    "    candidate_titles.append(graph['paper_nodes'][paper_ids[3]]['features']['title'])\n",
    "    candidate_titles.append(graph['paper_nodes'][paper_ids[4]]['features']['title'])\n",
    "    candidate_titles.append(graph['paper_nodes'][paper_ids[5]]['features']['title'])\n",
    "    candidate_titles.append(graph['paper_nodes'][paper_ids[6]]['features']['title'])\n",
    "    candidate_titles.append(graph['paper_nodes'][paper_ids[7]]['features']['title'])\n",
    "    candidate_titles.append(graph['paper_nodes'][paper_ids[8]]['features']['title'])\n",
    "    random.shuffle(candidate_titles)\n",
    "\n",
    "    generated_data.append({\"paper1_title\": graph['paper_nodes'][pair[0]]['features']['title'],\n",
    "                            \"paper2_title\": candidate_titles[0],\n",
    "                            \"paper3_title\": candidate_titles[1],\n",
    "                            \"paper4_title\": candidate_titles[2],\n",
    "                            \"paper5_title\": candidate_titles[3],\n",
    "                            \"paper6_title\": candidate_titles[4],\n",
    "                            \"paper7_title\": candidate_titles[5],\n",
    "                            \"paper8_title\": candidate_titles[6],\n",
    "                            \"paper9_title\": candidate_titles[7],\n",
    "                            \"paper10_title\": candidate_titles[8],\n",
    "                            \"paper11_title\": candidate_titles[9],\n",
    "                            \"paper_target_title\": graph['paper_nodes'][pair[1]]['features']['title']})\n",
    "\n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(all_generated_data, open(os.path.join(f'{domain}/preprocess_samples.pkl'), 'wb'))\n",
    "\n",
    "print('Saving file of #questions, ', len(all_generated_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
