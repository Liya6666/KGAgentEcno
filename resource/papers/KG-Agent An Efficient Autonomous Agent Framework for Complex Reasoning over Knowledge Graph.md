# KG-Agent: An Efficient Autonomous Agent Framework for Complex Reasoning over Knowledge Graph

## **🧠 一、研究背景：为什么做这件事？**

### **✅ 大模型（LLM）很强，但在知识推理上有短板：**

- LLM 的参数知识是静态的，无法实时更新。
- 面对**多跳、约束、比较类复杂问题**，容易出错或编造答案（幻觉）。
- 无法有效利用**结构化知识源**，如知识图谱（KG）。

### **✅ 知识图谱（KG）是理想的补充：**

- 包含大量结构化事实（如 Freebase、Wikidata）。
- 支持**多跳推理**（如“奥巴马的妻子的母校是哪个？”）。

### **❌ 但 LLM 不擅长“操作”KG：**

- 不会查图、不会执行逻辑、不会一步步推理。
- 现有方法要么：
    - **检索式**：把 KG 子图变成文本喂给 LLM，**丢失结构信息**；
    - **协同式**：让 LLM 和 KG 多轮交互，但**流程固定、不灵活**，且依赖大模型（如 GPT-4）。

---

## **🎯 二、研究目标：KG-Agent 要解决的问题**

### **表格**复制

| **问题** | **KG-Agent 的解决方案** |
| --- | --- |
| LLM 不会操作 KG | 提供**工具箱（Toolbox）**，让 LLM 能“调用函数”查图 |
| 推理流程固定 | 引入**自主决策机制**，每一步都由模型决定下一步操作 |
| 依赖大模型 | 用**小模型（7B）+指令微调**实现自主推理 |
| 数据需求大 | 只用 **10K 条样本**微调，效果超过全量训练的大模型 |

---

## **🧩 三、方法结构：KG-Agent 的三大模块**

### **✅ 1. Toolbox（工具箱）：让 LLM 能“操作”KG**

### **表格**复制

| **工具类型** | **功能示例** |
| --- | --- |
| **提取工具** | 获取实体、关系、类型、约束条件 |
| **逻辑工具** | 计数、交集、并集、判断、返回结果 |
| **语义工具** | 关系检索、实体消歧（用神经网络） |

> 每个工具都是一个函数，LLM 生成函数调用，如：get_tail_entity(Cristiano_Ronaldo, "team") → {m.050fh, ...}
> 

---

### **✅ 2. 指令微调：让 LLM 学会“如何一步步推理”**

### **🔧 步骤 1：从 KGQA 数据集中提取推理链**

- 每个问题有对应的 **SQL 查询**；
- 将 SQL 查询**映射为查询图**（query graph）；
- 用 BFS 遍历查询图，提取**推理链**（如：C罗 → 球队 → 年份 → 答案）。

### **🔧 步骤 2：将推理链转为“代码形式”**

- 每一步对应一个函数调用；
- 整个推理过程变成一段**可执行的程序**（KG Reasoning Program）。

### **🔧 步骤 3：构造指令微调数据**

- 每一步构造一个输入-输出对：
    - 输入：问题 + 当前 KG 信息 + 历史调用
    - 输出：下一步的函数调用
- 形成多轮推理轨迹，用于微调 LLaMA2-7B

---

### **✅ 3. 自主推理机制：LLM + 工具 + 记忆 + 执行器**

### **表格**复制

| **模块** | **作用** |
| --- | --- |
| **Planner（LLM）** | 根据当前记忆，决定下一步调用哪个工具 |
| **Executor** | 执行工具调用，返回结果 |
| **Knowledge Memory** | 存储当前实体、关系、历史调用等信息 |
| **迭代机制** | 每一步更新记忆，直到调用 `end()` 返回答案 |

> 就像让模型“在图上走”，每一步决定往哪个方向走，直到找到答案。
> 

---

## **📊 四、实验结果：为什么这很了不起？**

### **✅ 1. 内域数据集（KGQA）**

### **表格**复制

| **数据集** | **基准最佳** | **KG-Agent（10K 数据）** |
| --- | --- | --- |
| WebQSP | 83.4 | **83.3**（持平） |
| CWQ | 64.9 | **69.8**（+7.5%） |
| GrailQA | 83.1 | **86.3**（+2.7%） |

> 只用 10K 数据，LLaMA2-7B 打败全量训练的大模型
> 

---

### **✅ 2. 外域数据集（ODQA，Zero-shot）**

### **表格**复制

| **数据集** | **T5/BART 全量训练** | **KG-Agent（Zero-shot）** |
| --- | --- | --- |
| NQ-Wiki | ~32 | **33.0** |
| TQ-Wiki | ~33 | **35.9** |
| WQ-Freebase | ~26 | **28.9** |

> 没见过的数据，也能直接用，说明学到了“通用推理能力”
> 

---

### **✅ 3. 跨图谱迁移（MetaQA，电影领域）**

### **表格**复制

| **数据集** | **ChatGPT** | **StructGPT** | **KG-Agent（1-shot）** |
| --- | --- | --- | --- |
| MQA-3hop | 43.2 | 80.2 | **92.1** |

> 迁移到完全不同领域的 KG，依然最强
> 

---

## **🔍 五、进一步分析：它到底学到了什么？**

### **✅ 1. 数据量影响**

- 2K → 16K：性能提升明显
- 16K → 64K：提升有限

> 10K 是性价比最高的点
> 

### **✅ 2. 数据比例影响**

- 增加某一数据集比例 → 该数据集性能提升
- 但**平均性能下降** → 需要均衡采样

### **✅ 3. 工具重要性**

- 去掉逻辑工具 → 性能下降最明显
- 去掉语义工具 → 实体链接出错

---

## **🧭 六、意义与局限性**

### **✅ 意义：**

- 首次实现**小模型自主推理 KG**
- 不依赖大模型、不依赖大量数据
- 可迁移、可扩展、可解释（每一步都能追踪）

### **❌ 局限性：**

- 当前只支持**单一 KG 类型**（如 Freebase/Wikidata）
- 实体链接仍依赖外部工具
- 仅测试在**问答任务**上，未扩展到数据库、表格等
- 仅使用 LLaMA2-7B，未验证其他小模型（如 Mistral）

---

## **📌 总结一句话：**

> KG-Agent 让小模型“学会”了在知识图谱上“自己走”，不依赖大模型，也不用大量数据，就能完成复杂推理任务。
>